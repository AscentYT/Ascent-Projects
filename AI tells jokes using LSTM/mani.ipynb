{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4c3a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 02:18:11.128446: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-10 02:18:11.268904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752128291.321592     742 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752128291.339266     742 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752128291.471372     742 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752128291.471389     742 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752128291.471390     742 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752128291.471391     742 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-10 02:18:11.486525: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65191180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 70649\n",
      "Total sequences: 4082135\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 5  # Number of words in input\n",
    "\n",
    "# preparing data\n",
    "df = pd.read_csv(\"jokes.csv\")\n",
    "text = \" \".join(df['Joke'].astype(str).tolist()).lower()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(\"Vocab Size:\", total_words)\n",
    "\n",
    "input_sequences = []\n",
    "tokens = tokenizer.texts_to_sequences([text])[0]\n",
    "for i in range(sequence_length, len(tokens)):\n",
    "    n_gram_seq = tokens[i-sequence_length:i+1]\n",
    "    input_sequences.append(n_gram_seq)\n",
    "\n",
    "print(\"Total sequences:\", len(input_sequences))\n",
    "\n",
    "# 4. Pad & split into X/y\n",
    "input_sequences = np.array(input_sequences)\n",
    "X = input_sequences[:, :-1]  # all words except last\n",
    "y = input_sequences[:, -1]   # the last word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c31ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keshav/tensorflow-env/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1752034852.297762    1227 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m    1/31892\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:15:31\u001b[0m 1s/step - loss: 11.1656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752034854.088616    1363 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 14ms/step - loss: 6.2750\n",
      "Epoch 2/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 14ms/step - loss: 5.3006\n",
      "Epoch 3/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 14ms/step - loss: 5.0755\n",
      "Epoch 4/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 14ms/step - loss: 4.9323\n",
      "Epoch 5/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 14ms/step - loss: 4.8311\n",
      "Epoch 6/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 14ms/step - loss: 4.7466\n",
      "Epoch 7/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 14ms/step - loss: 4.6869\n",
      "Epoch 8/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 14ms/step - loss: 4.6405\n",
      "Epoch 9/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 14ms/step - loss: 4.5997\n",
      "Epoch 10/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 15ms/step - loss: 4.5645\n",
      "Epoch 11/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 15ms/step - loss: 4.5370\n",
      "Epoch 12/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 15ms/step - loss: 4.5040\n",
      "Epoch 13/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 15ms/step - loss: 4.4798\n",
      "Epoch 14/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 15ms/step - loss: 4.4577\n",
      "Epoch 15/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 15ms/step - loss: 4.4427\n",
      "Epoch 16/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 15ms/step - loss: 4.4236\n",
      "Epoch 17/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 15ms/step - loss: 4.4126\n",
      "Epoch 18/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m496s\u001b[0m 16ms/step - loss: 4.3979\n",
      "Epoch 19/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 16ms/step - loss: 4.3893\n",
      "Epoch 20/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 16ms/step - loss: 4.3783\n",
      "Epoch 21/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 16ms/step - loss: 4.3674\n",
      "Epoch 22/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 16ms/step - loss: 4.3578\n",
      "Epoch 23/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 16ms/step - loss: 4.3477\n",
      "Epoch 24/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 16ms/step - loss: 4.3388\n",
      "Epoch 25/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 16ms/step - loss: 4.3323\n",
      "Epoch 26/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 17ms/step - loss: 4.3274\n",
      "Epoch 27/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 17ms/step - loss: 4.3236\n",
      "Epoch 28/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 17ms/step - loss: 4.3165\n",
      "Epoch 29/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 17ms/step - loss: 4.3122\n",
      "Epoch 30/30\n",
      "\u001b[1m31892/31892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 17ms/step - loss: 4.3064\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "\tEmbedding(total_words, 100, input_length=sequence_length),\n",
    "\tLSTM(128),\n",
    "\tDense(total_words, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X, y, batch_size=128, epochs=30)\n",
    "model.save(\"joke_words_2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5aef13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knock knock who's there i was on\n"
     ]
    }
   ],
   "source": [
    "final_model = load_model(\"joke_words_2.keras\")\n",
    "\n",
    "def generate_text(seed_text, next_words=5, temperature=1.0):\n",
    "    result = seed_text.lower()\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([result])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=sequence_length, padding='pre')\n",
    "        predictions = final_model.predict(token_list, verbose=0)[0]\n",
    "\n",
    "        # Temperature sampling\n",
    "        preds = np.log(predictions + 1e-8) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        next_index = np.random.choice(len(preds), p=preds)\n",
    "        next_word = tokenizer.index_word.get(next_index, '')\n",
    "\n",
    "        # Termination logic\n",
    "        if not next_word.strip() or next_word in result.split()[-5:]:\n",
    "            break\n",
    "\n",
    "        result += ' ' + next_word\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example use\n",
    "your_line = \"Knock Knock\"\n",
    "seed = your_line.lower().split()[:sequence_length]\n",
    "print(generate_text(\" \".join(seed), temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679552c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff41aa-cd57-4850-ab0f-b2dd03047469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
